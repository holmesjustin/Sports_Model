{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamPath = '/Users/lorneez/projects/sports_predictor/Sports_Model/Data/teamData.csv'\n",
    "playerPath = '/Users/lorneez/projects/sports_predictor/Sports_Model/Data/playerData.csv'\n",
    "outcomePath = '/Users/lorneez/projects/sports_predictor/Sports_Model/Data/outcomeData.csv'\n",
    "teamData = pd.read_csv(teamPath)\n",
    "playerData = pd.read_csv(playerPath, engine='python')\n",
    "outcomeData = pd.read_csv(outcomePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomeData = outcomeData.drop([\"Start Time\", \"Box Score\", \"Notes\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomeData.loc[(outcomeData[\"OT?\"].isna()),'OT?']= 0\n",
    "outcomeData.loc[(outcomeData[\"OT?\"] == \"OT\"),'OT?']= 1\n",
    "outcomeData.loc[(outcomeData[\"OT?\"] == \"2OT\"),'OT?']= 2\n",
    "outcomeData.loc[(outcomeData[\"OT?\"] == \"3OT\"),'OT?']= 3\n",
    "outcomeData.loc[(outcomeData[\"OT?\"] == \"4OT\"),'OT?']= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redefineTeamNames(dataframe):\n",
    "    dataframe = dataframe.replace('Seattle SuperSonics', 'Oklahoma City Thunder', regex=True)\n",
    "    \n",
    "    dataframe = dataframe.replace('New Orleans/Oklahoma City Hornets', 'New Orleans Pelicans', regex=True)\n",
    "\n",
    "    dataframe = dataframe.replace('New Orleans Hornets', 'New Orleans Pelicans', regex=True)\n",
    "    \n",
    "    dataframe = dataframe.replace('Charlotte Bobcats', 'Charlotte Hornets', regex=True)\n",
    "    \n",
    "    dataframe = dataframe.replace('New Jersey Nets', 'Brooklyn Nets', regex=True)\n",
    "    \n",
    "#     dataframe = dataframe.replace('*', '', regex=True)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "outcomeData = redefineTeamNames(outcomeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homeWin(dataframe):\n",
    "    if dataframe['Winner'] == dataframe['Home']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "outcomeData['HomeWin'] = outcomeData.apply(homeWin, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = LabelEncoder()\n",
    "encoding.fit(outcomeData['Home'].values)\n",
    "outcomeData['Home'] = encoding.transform(outcomeData['Home'].values)\n",
    "outcomeData['Visitor'] = encoding.transform(outcomeData['Visitor'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurePath = '/Users/lorneez/projects/sports_predictor/Sports_Model/Data/DifferentialFeatureData.csv'\n",
    "X = pd.read_csv(featurePath)\n",
    "\n",
    "train_stats = X.describe()\n",
    "train_stats = train_stats.transpose()\n",
    "def norm(x):\n",
    "  return (x - train_stats['mean']) / train_stats['std']\n",
    "X = norm(X)\n",
    "\n",
    "\n",
    "y = outcomeData[\"HomeWin\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "validation_data = (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(64, activation='relu', kernel_initializer='random_normal', input_dim=113))\n",
    "classifier.add(Dropout(.5))\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(64, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dropout(.5))\n",
    "#Third  Hidden Layer\n",
    "classifier.add(Dense(64, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dropout(.5))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "\n",
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14303 samples, validate on 6131 samples\n",
      "Epoch 1/100\n",
      "14303/14303 [==============================] - 3s 239us/step - loss: 0.6228 - accuracy: 0.6401 - val_loss: 0.5853 - val_accuracy: 0.6836\n",
      "Epoch 2/100\n",
      "14303/14303 [==============================] - 1s 95us/step - loss: 0.5965 - accuracy: 0.6879 - val_loss: 0.5853 - val_accuracy: 0.6836\n",
      "Epoch 3/100\n",
      "14303/14303 [==============================] - 1s 94us/step - loss: 0.5935 - accuracy: 0.6883 - val_loss: 0.5829 - val_accuracy: 0.6904\n",
      "Epoch 4/100\n",
      "14303/14303 [==============================] - 2s 121us/step - loss: 0.5950 - accuracy: 0.6911 - val_loss: 0.5823 - val_accuracy: 0.6901\n",
      "Epoch 5/100\n",
      "14303/14303 [==============================] - 2s 138us/step - loss: 0.5911 - accuracy: 0.6915 - val_loss: 0.5828 - val_accuracy: 0.6899\n",
      "Epoch 6/100\n",
      "14303/14303 [==============================] - 1s 100us/step - loss: 0.5891 - accuracy: 0.6913 - val_loss: 0.5820 - val_accuracy: 0.6912\n",
      "Epoch 7/100\n",
      " 2432/14303 [====>.........................] - ETA: 2s - loss: 0.5912 - accuracy: 0.6854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorneez/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.223290). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n",
      "/Users/lorneez/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.113132). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14303/14303 [==============================] - 2s 131us/step - loss: 0.5890 - accuracy: 0.6945 - val_loss: 0.5817 - val_accuracy: 0.6893\n",
      "Epoch 8/100\n",
      "14303/14303 [==============================] - 1s 104us/step - loss: 0.5886 - accuracy: 0.6932 - val_loss: 0.5813 - val_accuracy: 0.6898\n",
      "Epoch 9/100\n",
      "14303/14303 [==============================] - 2s 114us/step - loss: 0.5866 - accuracy: 0.6966 - val_loss: 0.5808 - val_accuracy: 0.6924\n",
      "Epoch 10/100\n",
      "14303/14303 [==============================] - 1s 82us/step - loss: 0.5866 - accuracy: 0.6935 - val_loss: 0.5839 - val_accuracy: 0.6893\n",
      "Epoch 11/100\n",
      "14303/14303 [==============================] - 1s 95us/step - loss: 0.5875 - accuracy: 0.6950 - val_loss: 0.5828 - val_accuracy: 0.6890\n",
      "Epoch 12/100\n",
      "14303/14303 [==============================] - 2s 118us/step - loss: 0.5873 - accuracy: 0.6942 - val_loss: 0.5821 - val_accuracy: 0.6891\n",
      "Epoch 13/100\n",
      "14303/14303 [==============================] - 2s 165us/step - loss: 0.5887 - accuracy: 0.6928 - val_loss: 0.5838 - val_accuracy: 0.6885\n",
      "Epoch 14/100\n",
      "14303/14303 [==============================] - 2s 126us/step - loss: 0.5846 - accuracy: 0.6950 - val_loss: 0.5816 - val_accuracy: 0.6878\n",
      "Epoch 15/100\n",
      "14303/14303 [==============================] - 2s 125us/step - loss: 0.5851 - accuracy: 0.6967 - val_loss: 0.5833 - val_accuracy: 0.6893\n",
      "Epoch 16/100\n",
      "14303/14303 [==============================] - 2s 127us/step - loss: 0.5843 - accuracy: 0.6956 - val_loss: 0.5837 - val_accuracy: 0.6885\n",
      "Epoch 17/100\n",
      "14303/14303 [==============================] - 2s 109us/step - loss: 0.5858 - accuracy: 0.6974 - val_loss: 0.5816 - val_accuracy: 0.6881\n",
      "Epoch 18/100\n",
      "14303/14303 [==============================] - 2s 117us/step - loss: 0.5848 - accuracy: 0.6973 - val_loss: 0.5823 - val_accuracy: 0.6885\n",
      "Epoch 19/100\n",
      "14303/14303 [==============================] - 1s 102us/step - loss: 0.5863 - accuracy: 0.6942 - val_loss: 0.5819 - val_accuracy: 0.6912\n",
      "Epoch 00019: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a2762b590>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "#Fitting the data to the training dataset\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 10)\n",
    "classifier.fit(X_train,y_train, validation_data = validation_data, batch_size=128, epochs=100, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6131/6131 [==============================] - 1s 92us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5818697779111733, 0.6912412047386169]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eval_model=classifier.evaluate(X_train, y_train)\n",
    "#eval_model\n",
    "eval_model=classifier.evaluate(X_test, y_test)\n",
    "eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred=classifier.predict(X_test)\n",
    "y_pred =(y_pred> 0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1808  686]\n",
      " [1306 2331]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
